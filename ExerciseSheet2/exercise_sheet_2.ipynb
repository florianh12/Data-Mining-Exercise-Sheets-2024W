{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15178aa8-ddd4-4b94-8d76-ef300389efa0",
   "metadata": {},
   "source": [
    "# **Exercise Sheet 2: Clustering High-dimensional Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45615cbe-0a46-41b4-9f5c-6d80ad4c307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN, HDBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import densired as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94b35d-89db-4be4-b4e0-da4edcfb0676",
   "metadata": {},
   "source": [
    "## **Exercise 2-1** *Getting familiar with ClustPy*\n",
    "The purpose of this exercise is to get familiar with the Python library ClustPy, that is a library implementing\n",
    "many traditional and deep clustering algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b26f3-1787-4500-a630-b3bccf5773b9",
   "metadata": {},
   "source": [
    "### **a)** Please read the documentation of ClustPy at https://github.com/collinleiber/ClustPy. <br> Which deep clustering algorithms are currently implemented?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7def0e-835d-46c3-a976-88e9c20f52fe",
   "metadata": {},
   "source": [
    "- Auto-encoder Based Data Clustering (AEC)\n",
    "- Deep Clustering Network (DCN)\n",
    "- Deep Density-based Image Clustering (DDC)\n",
    "- Deep Embedded Clustering (DEC)\n",
    "- Improved Deep Embedded Clustering (IDEC)\n",
    "- Deep Embedded Cluster Tree (DeepECT)\n",
    "- Deep Embedded Clustering with k-Estimation (DipDECK)\n",
    "- DipEncoder\n",
    "- Deep k-Means (DKM)\n",
    "- Embedded Non-Redundant Clustering (ENRC)\n",
    "- Autoencoder Centroid-based Deep Cluster (ACeDeC, special case of ENRC)\n",
    "- Variational Deep Embedding (VaDE)\n",
    "- Not 2 Deep (N2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92038196-a19e-407e-a7dc-c6e2c5c5b2ad",
   "metadata": {},
   "source": [
    "### **b)** Either install ClustPy following the instructions at https://github.com/collinleiber/ClustPy for users or use Google Colaboratory https://colab.google/. Open and execute the Jupyter notebook provided here https://tinyurl.com/rltutorial2023. This notebook compares standard K-means with some deep clustering method on an example image data set. What is the clustering accuracy of standard K-means in terms of AMI? What is the clustering accuracy of the best deep clustering algorithm in this notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de1da1c-7d15-413d-91a2-7464deb9243b",
   "metadata": {},
   "source": [
    "K-Means\n",
    "- AMI: 63.80 (or 0.638 for not upscaled by 100.0)\n",
    "\n",
    "Best Deep Clustering (DEC)\n",
    "- AMI: 78.28 (or 0.7828 for not upscaled by 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386de4b-c786-4345-8ced-586251b70fd1",
   "metadata": {},
   "source": [
    "### **c)** Apply one additional deep clustering algorithm of your choice to the image data set and describe its results in comparison to the previous results. Just add this code to the Jupyter notebook available at https://tinyurl.com/rltutorial2023 to try it out. Afterwards, just submit this part as your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea776326-1e82-42c5-ae0a-0743914700e5",
   "metadata": {},
   "source": [
    "## Additional Clustering (ENRC)\n",
    "Worse in ACC, ARI, NMI and AMI compared to the best other clustering for both clusterings, but the second is better than the frist.\n",
    "### First Clustering\n",
    "ACC: 29.14, ARI: 12.69, NMI: 24.42, AMI: 24.38\n",
    "### Second Clustering\n",
    "ACC: 60.11, ARI: 54.46, NMI: 64.57, AMI: 64.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03773550-b415-4820-9cea-ea01b4389597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code only works in combination with the imports, functions and clusterings of the Tutorial jupyter notebook, \n",
    "# will produce errors when executed in this notebook\n",
    "from clustpy.deep import ENRC\n",
    "\n",
    "dec_name = \"enrc.pt\"\n",
    "\n",
    "TRAIN = False\n",
    "\n",
    "clustering_lr = 1e-4\n",
    "if TRAIN:\n",
    "    # load pretrained autoencoder\n",
    "    sd = torch.load(model_path)\n",
    "    ae.load_state_dict(sd)\n",
    "    ae.to(device)\n",
    "    ae.eval();\n",
    "\n",
    "    enrc = ENRC(n_clusters=[n_clusters,6],\n",
    "              clustering_epochs=150,\n",
    "              autoencoder=ae,\n",
    "              clustering_optimizer_params={\"lr\": clustering_lr},\n",
    "             )\n",
    "    enrc.fit(data.cpu().detach().numpy())\n",
    "\n",
    "    # save with joblib\n",
    "    joblib.dump(enrc, os.path.join(base_path, dec_name))\n",
    "else:\n",
    "    # load with joblib\n",
    "    enrc = joblib.load(os.path.join(base_path, dec_name))\n",
    "    enrc.autoencoder.to(device)\n",
    "print(\"KMeans - Clustering Result\")\n",
    "evaluate_clustering(labels, kmeans.labels_)\n",
    "print(\"\\nDCN - Clustering Result\")\n",
    "evaluate_clustering(labels, dcn.labels_)\n",
    "print(\"\\nDEC - Clustering Result\")\n",
    "evaluate_clustering(labels, dec.labels_)\n",
    "print(\"\\nIDEC - Clustering Result\")\n",
    "evaluate_clustering(labels, idec.labels_)\n",
    "print(\"\\nENRC - Clustering Result\")\n",
    "print(\"Clustering 1\")\n",
    "evaluate_clustering(labels, enrc.labels_[:,0])\n",
    "print(\"Clustering 2\")\n",
    "evaluate_clustering(labels, enrc.labels_[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228de492-902d-4ec3-937d-0c068ade1908",
   "metadata": {},
   "source": [
    "## **Exercise 2-2** *Implement Sychronization-based Clustering within ClustPy*\n",
    "This exercise focuses on implementing the *SynC* algorithm within ClustPy. Please note that you only have\n",
    "to implement the basic algorithm with pseudocode on Silde 15 of the lecture slides. The following materials\n",
    "might be helpful: The paper describing the algorithm *SynC*, you find it in Moodle; a Java implementation of\n",
    "the algorithm *SynC* is available here https://dm.uestc.edu.cn/wp-content/uploads/code/SynC.zip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a73bd8-bafb-42b3-8852-370a680e8bf5",
   "metadata": {},
   "source": [
    "### **a)** *Implement the basic algorithm **SynC** in ClustPy. Please observe the instructions **for developers** at https://github.com/collinleiber/ClustPy. Write a test for your code. Submit two files, one for the algorithm named **sync.py**, one for the test with name **testsync.py**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf63c62-1f56-4147-b7a1-94caae8ff10e",
   "metadata": {},
   "source": [
    "The algorithm works quite well in ClustPy and is located in clustpy.deep.\n",
    "The test file is located in the tests subdirectory.\n",
    "Both the sync.py and the testsync.py file are available in the main directory of the zip file as well (next to this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688639e-7582-4f56-af69-03b4f4545047",
   "metadata": {},
   "source": [
    "### **b)** *Evaluate your implementation (or the Java implementation of **SynC** if your Python implementation is not working) on the synthetic data set that you have created for Exercise 1-2 (at least 3 density-based clusters that cannot be correctly detected by k-Means). Briefly describe the results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45650395-a8bf-49bc-ba1f-92eecd74a8f9",
   "metadata": {},
   "source": [
    "Results:\n",
    "    NMI: 0.7446179258502434, ACC: 0.69, ARI: 0.6446044838728434, AMI: 0.7381557666768334\n",
    "\n",
    "The SynC algorithm falls into many of the pitfalls that the k-keans algorithm does and splits the moon clusters into two seperate clusters, but does quite well in all the metrics despite that fact"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
